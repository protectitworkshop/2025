<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <title>Security, Privacy and Information Theory Workshop (Protect-IT)
    (IEEE CSF 2024 Workshop)</title>
    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">
    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- MathJax -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script src="js/mathjax/es5/tex-mml-chtml.js"></script>
</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">

    <!-- Navigation -->
    <nav class="navbar navbar-custom navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse">
                    Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">
                    <span class="light" style="color: rgb(174, 105, 36);"> Protect-IT'24</span>

                </a>
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-right navbar-main-collapse">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#about" style="color: rgb(174, 105, 36);">Scope</a>

                    </li>
                    <li>
                        <a class="page-scroll" href="#dates" style="color: rgb(174, 105, 36);">CFP &amp; Dates</a>
                    </li>
                           <li>
                        <a class="page-scroll" href="#speakers" style="color: rgb(174, 105, 36);">Invited Speakers</a>
                    </li>
           
                    <li>
                        <a class="page-scroll" href="#schedule" style="color: rgb(174, 105, 36);"> Schedule</a>
                    </li>
                      <li>
                        <a class="page-scroll" href="#organizers" style="color: rgb(174, 105, 36);">Organization</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Intro Header -->
    <header class="intro">
        <div class="intro-body">
            <div class="container">
                <div class="row">
                    <div class="col-md-8 col-md-offset-2">
                        <h1 class="brand-heading">Security, Privacy and Information Theory</h1>
                        <p class="intro-text">
                            <a href="https://csf2024.ieee-security.org/index.html">IEEE CSF 2024</a> Workshop
                            <br />
                            July 8, 2024
                            <br>
                            Enschede, The Netherlands
                            <br /><br />
                            <a href="https://csf2024.ieee-security.org/registration.html" class="btn btn-black btn-lg">CSF Registration</a>
                        </p>
                        
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- About Section -->
    <section id="about" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Scope</h2>
                <p><a style="color: rgb(174, 105, 36);">Protect-IT</a> targets to attract studies on security and privacy for machine learning (ML) from an information-theoretic standpoint. Accuracy and efficiency of ML systems are ensured by employing large datasets which usually contain highly sensitive/personal information. This strong dependence on personal information jeopardizes the privacy and security of innocent Internet users who are contributing, knowingly or not, to these online statistical datasets. <a style="color: rgb(174, 105, 36);">Protect-IT</a> aims to bring the typical attendees of CSF, who have expertise on the theory of cryptography and (algorithmic) fairness together with researchers on information theory to study, develop, and evaluate privacy, security, and fairness attacks against ML along with defense strategies to counter them. We put information theory at the heart of this endeavor and call for contributions grounded in information-theoretic concepts and principles, aiming to enrich preliminary research efforts and to achieve widespread adoption.</p>
            </div>
        </div>
    </section>

   <!-- CFP & Dates Section -->
    <section id="dates" class="container content-section text-center">
      <div class="row">
        <div class="col-lg-8 col-lg-offset-2">
          <h2>Call For Papers &amp; Important Dates</h2>
          <a href="CFP-Protect-IT.pdf" class="btn btn-default btn-lg">Download Full CFP</a>
          <br />
          <br />
          <br />
          <p>
                    <b>Submission deadline</b>: <del>May 04, 2024, 23:59 (Anywhere on Earth) </del>
                    <br> <b> <font color="#ff0000"> May 13, 2024, 23:59 (Anywhere on Earth) </font> </b>
                    <br /><b>Notification of acceptance</b>: <del>June 04, 2024</del> June 07, 2024
                    <!-- <br /><b>CCS early <a -->
                    <!--                      href="https://csf2024.ieee-security.org/index.html">registration</a> -->
                    <!--   deadline</b>: TBD June 15, 2024 (11:59PM BST) -->
                    <!-- <br /><b>Workshop</b>: November 15, 2019 -->
          </p>
          <h3>Submission Instructions</h3>
          <p>
            We welcome two types of submissions: extended abstracts and posters. Extended abstracts must be at most 4 pages long excluding references and adhere to the CSF format. We encourage submissions of work that is new to the community of data privacy, security and information theory in addition to submissions which are currently under review elsewhere or recently published in privacy and security venues. The workshop  <b>will not</b> have formal proceedings, but authors of accepted abstracts can choose to publish their work on the workshop's webpage or to provide a link to arXiv.
          </p>
          <!-- <a href=" https://easychair.org/my/conference?conf=protectitl2024" class="btn btn-default btn-lg">Submit Your  Abstract</a> -->
        </div>
      </div>
    </section>

    <!-- Speakers Section -->
    <section id="speakers" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Invited Speakers</h2>
                <ul class="list-group">
                  <li class="list-group-item speaker"><a href="https://crises-deim.urv.cat/jdomingo/">Josep Domingo-Ferrer</a> (Universitat Rovira i Virgili)</li>
                    <li class="list-group-item speaker"><a href="http://researchers.lille.inria.fr/jramon/">Jan Ramon </a> (INRIA)</li>
                  </ul>
            </div>
        </div>
    </section>
    
  <!-- Schedule Section -->
    <section id="schedule" class="container content-section text-center">
        <div class="row">
            <div class="col-sm-8 col-sm-offset-2">
                <h2>Schedule</h2>
                <table class="table schedule">
                    <tbody>
                         <!-- Block slot -->
                         <tr>
                            <td colspan="2" class="block">Morning Session</td>
                        </tr>
                        <!-- Basic slot -->
                        <tr>
                            <td class="time">8:30 - 9:30</td>
                            <td class="slot">Registration</td>
                        </tr>
                        <!-- Invited slot -->
                        <tr>
                            <td class="time">9:30-10:30 </td>
                            <td class="slot talk">
                                <a href="#tabs1" data-toggle="collapse" class="accordion-toggle">
                                    Invited talk: <span style="font-weight:normal"> Josep Domingo-Ferrer
                                    &mdash;
                                    The accuracy, security, and privacy conflict in machine learning </span>
                                </a>
                            </td>
                        </tr>
                     <!-- Basic slot -->
                        <tr>
                            <td class="time">10:30 - 11:00 </td>
                            <td class="slot">Coffee break</td>
                        </tr>
                        <!-- Basic slot -->
                        <tr>
                            <td class="time">11:00 - 12:30  </td>
                            <td class="slot"><b> Session 1: Federated learning and secure computation</b> </td>
                        </tr>
                        <tr>
                            <td class="time">11:00–11:30</td>
                            <td class="slot talk">
                                <a href="#tabs2" data-toggle="collapse" class="accordion-toggle">
                                    Bayes’ capacity as a measure for reconstruction attacks in federated learning.
                                    <br> <span style="font-weight:normal"> Natasha Fernandes (Macquarie University), Sayan Biswas (EPFL), Annabelle McIver (Macquarie University), Parastoo Sadeghi (UNSW Canberra), Pedro Faustini (Macquarie University), Mark Dras (Macquarie University) and Catuscia Palamidessi (Inria and Ecole Polytechnique) </span>
                                </a>
                            </td>
                        </tr>
                        <tr>
                            <td colspan="2" class="hiddenRow">
                                <div class="accordion-body collapse talk-abstract"  id="tabs2">
                                    Within the machine learning community, reconstruction attacks are a principal attack of concern and have been identified even in federated learning, which was designed with privacy-preservation in mind. In federated learning, it has been shown that an adversary with knowledge of the machine learning architecture is able to infer the exact value of a training element given an observation of the weight updates performed during stochastic gradient descent. In response to these threats the privacy community recommends the use of differential privacy in the stochastic gradient descent algorithm, termed DP-SGD. However, DP has not yet been formally established as an effective counter-measure against reconstruction attacks. In this paper we formalise the reconstruction threat model using the information-theoretic framework of quantitative information flow. We show that the Bayes' capacity, related to the Sibson mutual information of order infinity, represents a tight upper bound on the leakage of the DP-SGD algorithm to an adversary interested in performing a reconstruction attack. We provide empirical results demonstrating the effectiveness of this measure for comparing mechanisms against reconstruction threats.
                                </div>
                            </td>
                        </tr>

                        <tr>
                            <td class="time">11:30–12:00</td>
                            <td class="slot talk">
                                <a href="#tabs3" data-toggle="collapse" class="accordion-toggle">
                                    Verifiable cross-silo federated learning.
                                    <br> <span style="font-weight:normal"> Aleksei Korneev (INRIA Lille, University of Lille) and Jan Ramon (INRIA Lille) </span>
                                </a>
                            </td>
                        </tr>
                        <tr>
                            <td colspan="2" class="hiddenRow">
                                <div class="accordion-body collapse talk-abstract"  id="tabs3">
                                    Federated Learning (FL) is a widespread approach that allows training machine learning (ML) models with data distributed across multiple devices. In cross-silo FL, which often appears in domains like healthcare or finance, the number of participants is moderate, and each party typically represents a well-known organization. However, malicious agents may still attempt to disturb the training procedure in order to obtain certain benefits, for example, a biased result or a reduction in computational load. While one can easily detect a malicious agent when data used for training is public, the problem becomes much more acute when it is necessary to maintain the privacy of the training dataset. To address this issue, there is recently growing interest in developing verifiable protocols, where one can check that parties do not deviate from the training procedure and perform computations correctly. In this paper, we conduct a comprehensive analysis of such protocols, and fit them in a taxonomy. We perform a comparison of the efficiency and threat models of various approaches. We next identify research gaps and discuss potential directions for future scientific work.
                                </div>
                            </td>
                        </tr>

                        <tr>
                            <td class="time">12:00–12:30</td>
                            <td class="slot talk">
                                <a href="#tabs4" data-toggle="collapse" class="accordion-toggle">
                                    Overview on Secure Comparison.
                                    <br> <span style="font-weight:normal"> Quentin Sinh (INRIA Lille) and Jan Ramon (INRIA Lille) </span>
                                </a>
                            </td>
                        </tr>
                        <tr>
                            <td colspan="2" class="hiddenRow">
                                <div class="accordion-body collapse talk-abstract"  id="tabs4">
                                    Introduced by Yao’s Millionaires’ problem, Secure Comparison (SC) allows parties to compare two secrets in a privacy-preserving manner. This article gives an overview of the different SC techniques in various settings such as Secret Sharing (SS) or Homomorphic Encryption (HE).
                                </div>
                            </td>
                        </tr>
                        
                        <!-- Basic slot -->
                        <tr>
                            <td class="time">12:30–14:00</td>
                            <td class="slot">Lunch break</td>
                        </tr>


                         <!-- Block slot -->
                         <tr>
                            <td colspan="2" class="block">Afternoon Session</td>
                        </tr>
                        <!-- Invited slot -->
                        <tr>
                            <td class="time">14:00–15:00</td>
                            <td class="slot talk">
                                <a href="#tabs123" data-toggle="collapse" class="accordion-toggle">
                                    Invited talk: <span style="font-weight:normal"> Jan Ramon
                                    &mdash;
                                    Applying differential privacy theory in practical applications </span>
                                </a>
                            </td>
                        </tr>
                       
                     
                        <!-- Basic slot -->
                        <tr>
                            <td class="time">15:00–15:30</td>
                            <td class="slot">Coffee break</td>
                        </tr>

                        <tr>
                            <td class="time">15:30 - 17:00  </td>
                            <td class="slot"><b> Session 2: Differential privacy and security attacks</b> </td>
                        </tr>
                        <tr>
                            <td class="time">15:30–16:00</td>
                            <td class="slot talk">
                                <a href="#tabs11" data-toggle="collapse" class="accordion-toggle">
                                    Node injection link stealing attack.
                                    <br> <span style="font-weight:normal"> Oualid Zari (EURECOM), Javier Parra-Arnau (Universitat Politècnica de Catalunya), Ayşe Ünsal (EURECOM) and Melek Önen (EURECOM) </span>
                                </a>
                            </td>
                        </tr>
                        <tr>
                            <td colspan="2" class="hiddenRow">
                                <div class="accordion-body collapse talk-abstract"  id="tabs11">
                                    In this paper, we present a stealthy and effective attack that exposes privacy vulnerabilities in Graph Neural Networks (GNNs) by inferring private links within graph-structured data. Focusing on dynamic GNNs, we propose to inject new nodes and attach them to a particular target node to infer its private edge information. Our approach significantly enhances the F1 score of the attack beyond the current state-of-the-art benchmarks. Specifically, for the Twitch dataset, our method improves the F1 score by 23.75%, and for the Flickr dataset, it records a remarkable improvement, where the new performance is more than three times better than the state-of-the-art. We also propose and evaluate defense strategies based on differentially private (DP) mechanisms relying on a newly defined DP notion, which, on average, reduce the effectiveness of the attack by approximately 71.9% while only incurring a minimal average utility loss of about 3.2%.
                                </div>
                            </td>
                        </tr>

                        <tr>
                            <td class="time">16:00–16:30</td>
                            <td class="slot talk">
                                <a href="#tabs22" data-toggle="collapse" class="accordion-toggle">
                                    Secure latent dirichlet allocation.
                                    <br> <span style="font-weight:normal"> Thijs Veugen (Netherlands Organisation for Applied Scientific Research), Vincent Dunning (Netherlands Organisation for Applied Scientific Research), Michiel Marcus (Netherlands Organisation for Applied Scientific Research) and Bart Kamphorst (Netherlands Organisation for Applied Scientific Research) </span>
                                </a>
                            </td>
                        </tr>
                        <tr>
                            <td colspan="2" class="hiddenRow">
                                <div class="accordion-body collapse talk-abstract"  id="tabs22">
                                    Topic modeling refers to a popular set of techniques used to discover hidden topics that occur in a collection of documents. These topics can, for example, be used to categorize documents or label text for further processing. One popular topic modeling technique is Latent Dirichlet Allocation (LDA). In topic modeling scenarios, the documents are often assumed to be in one, centralized dataset. However, sometimes documents are held by different parties, and contain privacy- or commercially-sensitive information that cannot be shared. We present a novel, decentralized approach to train an LDA model securely without having to share any information about the content of the documents with the other parties. We preserve the privacy of the individual parties using secure multi-party computation (MPC), achieving similar accuracy compared to an (insecure) centralised approach. With $1024$-bit Paillier keys, a topic model with $5$ topics and $3000$ words can be trained in around $16$ hours. Furthermore, we show that the solution scales linearly in the total number of words and the number of topics.
                                </div>
                            </td>
                        </tr>

                        <tr>
                            <td class="time">16:30–17:00</td>
                            <td class="slot talk">
                                <a href="#tabs33" data-toggle="collapse" class="accordion-toggle">
                                    Probabilistic parallel composition theorems for differential privacy.
                                    <br> <span style="font-weight:normal"> Àlex Miranda-Pascual (Karlsruhe Institute of Technology, Universitat Politècnica de Catalunya), Javier Parra-Arnau (Universitat Politècnica de Catalunya ) and Thorsten Strufe (Karlsruhe Institute of Technology) </span>
                                </a>
                            </td>
                        </tr>
                        <tr>
                            <td colspan="2" class="hiddenRow">
                                <div class="accordion-body collapse talk-abstract"  id="tabs33">
                                    In this short abstract, we present new composition results for (epsilon,delta)-DP that go even further, namely, probabilistic parallel composition. In this new composition scenario, the mechanisms take as input disjoint subsets of the initial database, as in parallel composition, but where the input subsets are chosen randomly instead of deterministically. We provide two theorems with different ways to randomly select the inputs: The first, defined for unbounded DP, samples each record into a single input according to a fixed distribution; while the second, defined for bounded DP, samples subsets of fixed size uniformly. Notably, these new composition methods improve privacy by introducing uncertainty, and allow us to obtain lower privacy parameters than those obtained by the classical parallel composition results. We believe these new techniques can be useful for the future design of DP mechanisms.
                                </div>
                            </td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
    </section>
    
    

    

    <!-- Organizers Section -->
    <section id="organizers" class="container content-section text-center">
    <div class="row">
        <div class="col-lg-8 col-lg-offset-2">
            <h2><a>Organization</a></h2>
            <br />
            <h3>Workshop chairs</h3>
            <ul class="list-group">
                <li class="list-group-item organizer">Ayşe Ünsal, EURECOM</li>
                <li class="list-group-item organizer">Javier Parra Arnau, Universitat Politècnica de Catalunya</li>
                </ul>
            <br />
            <h3>Publications chair</h3>
            <ul class="list-group">
                <li class="list-group-item organizer">Melek Önen, EURECOM</li>
            </ul>
            <br />
           
            <h3>Organizers</h3>
            <ul class="list-group">
                <li class="list-group-item organizer">Víctor Rubio Jornet, Universitat Politècnica de Catalunya, UPC</li>
            </ul>
            <br />

            <h3>Program Committee</h3>
            <ul class="list-group">
                <li class="list-group-item organizer">Aurélien Bellet, INRIA</li>
                <li class="list-group-item organizer">Josep Domingo-Ferrer, University of Rovira i Virgili</li>
                <li class="list-group-item organizer">Sébastien Gambs, Université du Québec à Montréal</li>
                <li class="list-group-item organizer">Cédric Gouy-Pailler, CEA</li>
                <li class="list-group-item organizer">Emre Gürsoy, Koç University</li>
                <li class="list-group-item organizer">Arun Padakandla, EURECOM</li>
                <li class="list-group-item organizer">Jan Ramon, INRIA</li>
                <li class="list-group-item organizer">Vicenç Torra, Umeå University</li>   
                <li class="list-group-item organizer">Weizhi Meng, Technical University of Denmark</li>   
            </ul>
            <br />
            <img style="margin:40px;" height="60" src="img/sponsor-01.png">
            <img style="margin:70px;" height="80" src="img/sponsor-02.png">
        </div>
    </div>
    </section>


    <!-- Footer -->
    <footer>
        <div class="container text-center">
            <p>Contact us: <a href="mailto:protectitworkshop@gmail.com">protectitworkshop@gmail.com</a></p>
            <br />
        </div>
    </footer>
    <!-- jQuery -->
    <script src="js/jquery.min.js"></script>
    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>
    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <!-- Theme JavaScript -->
    <script src="js/script.js"></script>
</body>

</html>
